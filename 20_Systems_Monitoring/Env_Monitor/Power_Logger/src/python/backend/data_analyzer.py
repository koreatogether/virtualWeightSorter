#!/usr/bin/env python3
"""
INA219 Power Monitoring System - Data Analyzer
Phase 4.1: ì´ë™í‰ê·  + ì´ìƒì¹˜ íƒì§€ ì‹œìŠ¤í…œ

ê¸°ëŠ¥:
- ì´ë™í‰ê·  ê³„ì‚° (1ë¶„, 5ë¶„, 15ë¶„)
- ì´ìƒì¹˜ íƒì§€ (Z-score, IQR ë°©ë²•)
- ì‹¤ì‹œê°„ í†µê³„ ë¶„ì„
- ë°ì´í„° í’ˆì§ˆ í‰ê°€
"""

import sqlite3
import statistics
from collections import deque
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Optional

import numpy as np


@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""

    timestamp: datetime
    value: float
    moving_avg_1m: float
    moving_avg_5m: float
    moving_avg_15m: float
    is_outlier: bool
    outlier_score: float
    outlier_method: str
    confidence: float


@dataclass
class OutlierStats:
    """ì´ìƒì¹˜ í†µê³„ ë°ì´í„° í´ë˜ìŠ¤"""

    total_samples: int
    outlier_count: int
    outlier_rate: float
    last_outlier_time: Optional[datetime]
    severity_distribution: dict[str, int]  # mild, moderate, severe


class MovingAverageCalculator:
    """ì´ë™í‰ê·  ê³„ì‚°ê¸°"""

    def __init__(self, window_sizes: dict[str, int] = None):
        if window_sizes is None:
            window_sizes = {
                "1m": 60,  # 1ë¶„ = 60ì´ˆ (1ì´ˆ ê°„ê²© ë°ì´í„°)
                "5m": 300,  # 5ë¶„ = 300ì´ˆ
                "15m": 900,  # 15ë¶„ = 900ì´ˆ
            }

        self.window_sizes = window_sizes
        self.data_buffers = {
            "voltage": {key: deque(maxlen=size) for key, size in window_sizes.items()},
            "current": {key: deque(maxlen=size) for key, size in window_sizes.items()},
            "power": {key: deque(maxlen=size) for key, size in window_sizes.items()},
        }

    def add_data(self, voltage: float, current: float, power: float):
        """ìƒˆ ë°ì´í„° ì¶”ê°€"""
        for metric in ["voltage", "current", "power"]:
            value = locals()[metric]
            for window in self.data_buffers[metric]:
                self.data_buffers[metric][window].append(value)

    def get_moving_averages(self, metric: str) -> dict[str, float]:
        """ì§€ì •ëœ ë©”íŠ¸ë¦­ì˜ ì´ë™í‰ê·  ê³„ì‚°"""
        if metric not in self.data_buffers:
            return {}

        averages = {}
        for window, buffer in self.data_buffers[metric].items():
            if len(buffer) > 0:
                averages[window] = statistics.mean(buffer)
            else:
                averages[window] = 0.0

        return averages

    def get_all_moving_averages(self) -> dict[str, dict[str, float]]:
        """ëª¨ë“  ë©”íŠ¸ë¦­ì˜ ì´ë™í‰ê·  ê³„ì‚°"""
        return {
            metric: self.get_moving_averages(metric)
            for metric in self.data_buffers.keys()
        }


class OutlierDetector:
    """ì´ìƒì¹˜ íƒì§€ê¸°"""

    def __init__(
        self,
        z_threshold: float = 2.5,
        iqr_multiplier: float = 1.5,
        min_samples: int = 30,
    ):
        self.z_threshold = z_threshold
        self.iqr_multiplier = iqr_multiplier
        self.min_samples = min_samples

        # ë°ì´í„° ë²„í¼ (ìµœê·¼ 1000ê°œ ë°ì´í„° ìœ ì§€)
        self.data_history = {
            "voltage": deque(maxlen=1000),
            "current": deque(maxlen=1000),
            "power": deque(maxlen=1000),
        }

    def add_data(self, voltage: float, current: float, power: float):
        """ìƒˆ ë°ì´í„° ì¶”ê°€"""
        self.data_history["voltage"].append(voltage)
        self.data_history["current"].append(current)
        self.data_history["power"].append(power)

    def detect_outliers_zscore(self, metric: str, value: float) -> tuple[bool, float]:
        """Z-score ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ íƒì§€"""
        if metric not in self.data_history:
            return False, 0.0

        data = list(self.data_history[metric])
        if len(data) < self.min_samples:
            return False, 0.0

        try:
            mean = statistics.mean(data)
            stdev = statistics.stdev(data)

            if stdev == 0:
                return False, 0.0

            z_score = abs((value - mean) / stdev)
            is_outlier = z_score > self.z_threshold

            return is_outlier, z_score

        except Exception:
            return False, 0.0

    def detect_outliers_iqr(self, metric: str, value: float) -> tuple[bool, float]:
        """IQR ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ íƒì§€"""
        if metric not in self.data_history:
            return False, 0.0

        data = list(self.data_history[metric])
        if len(data) < self.min_samples:
            return False, 0.0

        try:
            data_sorted = sorted(data)
            n = len(data_sorted)

            q1_idx = n // 4
            q3_idx = 3 * n // 4

            q1 = data_sorted[q1_idx]
            q3 = data_sorted[q3_idx]
            iqr = q3 - q1

            if iqr == 0:
                return False, 0.0

            lower_bound = q1 - self.iqr_multiplier * iqr
            upper_bound = q3 + self.iqr_multiplier * iqr

            is_outlier = value < lower_bound or value > upper_bound

            # IQR ì ìˆ˜ ê³„ì‚° (ê²½ê³„ë¡œë¶€í„°ì˜ ê±°ë¦¬)
            if value < lower_bound:
                iqr_score = (lower_bound - value) / iqr
            elif value > upper_bound:
                iqr_score = (value - upper_bound) / iqr
            else:
                iqr_score = 0.0

            return is_outlier, iqr_score

        except Exception:
            return False, 0.0

    def detect_outlier(self, metric: str, value: float) -> dict[str, Any]:
        """ì¢…í•© ì´ìƒì¹˜ íƒì§€"""
        # Z-score ë°©ë²•
        z_outlier, z_score = self.detect_outliers_zscore(metric, value)

        # IQR ë°©ë²•
        iqr_outlier, iqr_score = self.detect_outliers_iqr(metric, value)

        # ë‘ ë°©ë²• ì¤‘ í•˜ë‚˜ë¼ë„ ì´ìƒì¹˜ë¡œ íŒë‹¨í•˜ë©´ ì´ìƒì¹˜ë¡œ ë¶„ë¥˜
        is_outlier = z_outlier or iqr_outlier

        # ë” ë†’ì€ ì ìˆ˜ë¥¼ ì‚¬ìš©
        if z_score > iqr_score:
            primary_method = "z-score"
            primary_score = z_score
        else:
            primary_method = "iqr"
            primary_score = iqr_score

        # ì‹ ë¢°ë„ ê³„ì‚° (ë°ì´í„° ìƒ˜í”Œ ìˆ˜ ê¸°ë°˜)
        sample_count = len(self.data_history[metric])
        confidence = min(sample_count / 100.0, 1.0)  # 100ê°œ ìƒ˜í”Œì—ì„œ 100% ì‹ ë¢°ë„

        # ì‹¬ê°ë„ ë¶„ë¥˜
        if primary_score > 4.0:
            severity = "severe"
        elif primary_score > 2.5:
            severity = "moderate"
        else:
            severity = "mild"

        return {
            "is_outlier": is_outlier,
            "method": primary_method,
            "score": primary_score,
            "z_score": z_score,
            "iqr_score": iqr_score,
            "confidence": confidence,
            "severity": severity,
            "sample_count": sample_count,
        }


class DataAnalyzer:
    """ë°ì´í„° ë¶„ì„ê¸° ë©”ì¸ í´ë˜ìŠ¤"""

    def __init__(self, db_path: str = "power_monitoring.db"):
        self.db_path = db_path
        self.moving_avg_calc = MovingAverageCalculator()
        self.outlier_detector = OutlierDetector()

        # ì´ìƒì¹˜ í†µê³„
        self.outlier_stats = {
            "voltage": OutlierStats(
                0, 0, 0.0, None, {"mild": 0, "moderate": 0, "severe": 0}
            ),
            "current": OutlierStats(
                0, 0, 0.0, None, {"mild": 0, "moderate": 0, "severe": 0}
            ),
            "power": OutlierStats(
                0, 0, 0.0, None, {"mild": 0, "moderate": 0, "severe": 0}
            ),
        }

        # ìµœê·¼ ë¶„ì„ ê²°ê³¼ (ì°¨íŠ¸ í‘œì‹œìš©)
        self.recent_results = deque(maxlen=1000)

    def analyze_data_point(
        self, voltage: float, current: float, power: float
    ) -> dict[str, Any]:
        """ë‹¨ì¼ ë°ì´í„° í¬ì¸íŠ¸ ë¶„ì„"""
        timestamp = datetime.now()

        # ì´ë™í‰ê·  ê³„ì‚°ê¸°ì— ë°ì´í„° ì¶”ê°€
        self.moving_avg_calc.add_data(voltage, current, power)

        # ì´ìƒì¹˜ íƒì§€ê¸°ì— ë°ì´í„° ì¶”ê°€
        self.outlier_detector.add_data(voltage, current, power)

        # ì´ë™í‰ê·  ê³„ì‚°
        moving_averages = self.moving_avg_calc.get_all_moving_averages()

        # ê° ë©”íŠ¸ë¦­ë³„ ì´ìƒì¹˜ íƒì§€
        analysis_results = {}

        for metric, value in [
            ("voltage", voltage),
            ("current", current),
            ("power", power),
        ]:
            outlier_result = self.outlier_detector.detect_outlier(metric, value)

            # í†µê³„ ì—…ë°ì´íŠ¸
            stats = self.outlier_stats[metric]
            stats.total_samples += 1

            if outlier_result["is_outlier"]:
                stats.outlier_count += 1
                stats.last_outlier_time = timestamp
                stats.severity_distribution[outlier_result["severity"]] += 1

            stats.outlier_rate = (
                stats.outlier_count / stats.total_samples
                if stats.total_samples > 0
                else 0.0
            )

            # ë¶„ì„ ê²°ê³¼ êµ¬ì„±
            analysis_results[metric] = {
                "value": value,
                "moving_avg": moving_averages[metric],
                "outlier": outlier_result,
                "stats": {
                    "total_samples": stats.total_samples,
                    "outlier_count": stats.outlier_count,
                    "outlier_rate": stats.outlier_rate,
                    "last_outlier_time": (
                        stats.last_outlier_time.isoformat()
                        if stats.last_outlier_time
                        else None
                    ),
                },
            }

        # ì „ì²´ ë¶„ì„ ê²°ê³¼
        overall_result = {
            "timestamp": timestamp.isoformat(),
            "metrics": analysis_results,
            "has_any_outlier": any(
                analysis_results[m]["outlier"]["is_outlier"] for m in analysis_results
            ),
            "outlier_count": sum(
                1
                for m in analysis_results
                if analysis_results[m]["outlier"]["is_outlier"]
            ),
            "confidence": statistics.mean(
                [analysis_results[m]["outlier"]["confidence"] for m in analysis_results]
            ),
        }

        # ìµœê·¼ ê²°ê³¼ì— ì¶”ê°€
        self.recent_results.append(overall_result)

        return overall_result

    def get_outlier_summary(self) -> dict[str, Any]:
        """ì´ìƒì¹˜ ìš”ì•½ í†µê³„"""
        summary = {}

        for metric, stats in self.outlier_stats.items():
            summary[metric] = {
                "total_samples": stats.total_samples,
                "outlier_count": stats.outlier_count,
                "outlier_rate": round(stats.outlier_rate * 100, 2),  # ë°±ë¶„ìœ¨
                "last_outlier_time": (
                    stats.last_outlier_time.isoformat()
                    if stats.last_outlier_time
                    else None
                ),
                "severity_distribution": stats.severity_distribution.copy(),
            }

        # ì „ì²´ í†µê³„
        total_samples = sum(
            stats.total_samples for stats in self.outlier_stats.values()
        )
        total_outliers = sum(
            stats.outlier_count for stats in self.outlier_stats.values()
        )

        summary["overall"] = {
            "total_samples": total_samples,
            "total_outliers": total_outliers,
            "overall_outlier_rate": round(
                (total_outliers / total_samples * 100) if total_samples > 0 else 0, 2
            ),
            "metrics_with_outliers": sum(
                1 for stats in self.outlier_stats.values() if stats.outlier_count > 0
            ),
        }

        return summary

    def get_recent_outliers(self, limit: int = 10) -> list[dict[str, Any]]:
        """ìµœê·¼ ì´ìƒì¹˜ ëª©ë¡"""
        outliers = []

        for result in reversed(self.recent_results):
            if result["has_any_outlier"]:
                outlier_metrics = []
                for metric, data in result["metrics"].items():
                    if data["outlier"]["is_outlier"]:
                        outlier_metrics.append(
                            {
                                "metric": metric,
                                "value": data["value"],
                                "score": data["outlier"]["score"],
                                "severity": data["outlier"]["severity"],
                                "method": data["outlier"]["method"],
                            }
                        )

                outliers.append(
                    {
                        "timestamp": result["timestamp"],
                        "outlier_count": result["outlier_count"],
                        "confidence": result["confidence"],
                        "metrics": outlier_metrics,
                    }
                )

                if len(outliers) >= limit:
                    break

        return outliers

    def save_analysis_to_db(self, analysis_result: dict[str, Any]):
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # ë¶„ì„ ê²°ê³¼ í…Œì´ë¸” ìƒì„± (ì—†ìœ¼ë©´)
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS analysis_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    metric TEXT NOT NULL,
                    value REAL NOT NULL,
                    moving_avg_1m REAL,
                    moving_avg_5m REAL,
                    moving_avg_15m REAL,
                    is_outlier BOOLEAN NOT NULL,
                    outlier_score REAL,
                    outlier_method TEXT,
                    severity TEXT,
                    confidence REAL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """
            )

            # ê° ë©”íŠ¸ë¦­ë³„ ê²°ê³¼ ì €ì¥
            for metric, data in analysis_result["metrics"].items():
                cursor.execute(
                    """
                    INSERT INTO analysis_results
                    (timestamp, metric, value, moving_avg_1m, moving_avg_5m, moving_avg_15m,
                     is_outlier, outlier_score, outlier_method, severity, confidence)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                    (
                        analysis_result["timestamp"],
                        metric,
                        data["value"],
                        data["moving_avg"].get("1m", 0),
                        data["moving_avg"].get("5m", 0),
                        data["moving_avg"].get("15m", 0),
                        data["outlier"]["is_outlier"],
                        data["outlier"]["score"],
                        data["outlier"]["method"],
                        data["outlier"]["severity"],
                        data["outlier"]["confidence"],
                    ),
                )

            conn.commit()
            conn.close()

        except Exception as e:
            print(f"Error saving analysis to database: {e}")


# í…ŒìŠ¤íŠ¸ ë° ë°ëª¨ í•¨ìˆ˜
def demo_data_analyzer():
    """ë°ì´í„° ë¶„ì„ê¸° ë°ëª¨"""
    print("ğŸ” Data Analyzer Demo")
    print("=" * 40)

    analyzer = DataAnalyzer()

    # ì •ìƒ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜
    print("ğŸ“Š Adding normal data...")
    for i in range(50):
        voltage = 5.0 + np.random.normal(0, 0.02)  # ì •ìƒ ë²”ìœ„
        current = 0.25 + np.random.normal(0, 0.01)
        power = voltage * current

        result = analyzer.analyze_data_point(voltage, current, power)

        if i % 10 == 0:
            print(f"  Sample {i+1}: V={voltage:.3f}V, A={current:.3f}A, W={power:.3f}W")

    # ì´ìƒì¹˜ ë°ì´í„° ì¶”ê°€
    print("\nâš ï¸ Adding outlier data...")
    outlier_data = [
        (6.5, 0.25, 1.625),  # ì „ì•• ì´ìƒì¹˜
        (5.0, 0.8, 4.0),  # ì „ë¥˜ ì´ìƒì¹˜
        (5.0, 0.25, 2.5),  # ì „ë ¥ ì´ìƒì¹˜ (ê³„ì‚° ë¶ˆì¼ì¹˜)
    ]

    for voltage, current, power in outlier_data:
        result = analyzer.analyze_data_point(voltage, current, power)
        print(f"  Outlier: V={voltage:.3f}V, A={current:.3f}A, W={power:.3f}W")

        if result["has_any_outlier"]:
            print(f"    ğŸš¨ Detected {result['outlier_count']} outlier(s)")

    # í†µê³„ ìš”ì•½
    print("\nğŸ“ˆ Analysis Summary:")
    summary = analyzer.get_outlier_summary()

    for metric, stats in summary.items():
        if metric != "overall":
            print(f"  {metric.capitalize()}:")
            print(f"    Samples: {stats['total_samples']}")
            print(f"    Outliers: {stats['outlier_count']} ({stats['outlier_rate']}%)")

    print(f"\nğŸ¯ Overall outlier rate: {summary['overall']['overall_outlier_rate']}%")

    # ìµœê·¼ ì´ìƒì¹˜
    recent_outliers = analyzer.get_recent_outliers(5)
    if recent_outliers:
        print(f"\nğŸš¨ Recent outliers ({len(recent_outliers)}):")
        for outlier in recent_outliers:
            print(f"  {outlier['timestamp']}: {outlier['outlier_count']} outlier(s)")


if __name__ == "__main__":
    demo_data_analyzer()
